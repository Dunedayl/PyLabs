{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('cats_and_dogs_small_2.h5')\n",
    "model.summary()  # As a reminder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/Users/fchollet/Downloads/cats_and_dogs_small/test/cats/cat.1700.jpg'\n",
    "\n",
    "# We preprocess the image into a 4D tensor\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "# Remember that the model was trained on inputs\n",
    "# that were preprocessed in the following way:\n",
    "img_tensor /= 255.\n",
    "\n",
    "# Its shape is (1, 150, 150, 3)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "# Extracts the outputs of the top 8 layers:\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a list of 5 Numpy arrays:\n",
    "# one array per layer activation\n",
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(first_layer_activation[0, :, :, 3], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(first_layer_activation[0, :, :, 30], cmap='viridis')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = []\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "model = VGG16(weights='imagenet',\n",
    "              include_top=False)\n",
    "\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The call to `gradients` returns a list of tensors (of size 1 in this case)\n",
    "# hence we only keep the first element -- which is a tensor.\n",
    "grads = K.gradients(loss, model.input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate = K.function([model.input], [loss, grads])\n",
    "\n",
    "# Let's test it:\n",
    "import numpy as np\n",
    "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from a gray image with some noise\n",
    "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128.\n",
    "\n",
    "# Run gradient ascent for 40 steps\n",
    "step = 1.  # this is the magnitude of each gradient update\n",
    "for i in range(40):\n",
    "    # Compute the loss value and gradient value\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    # Here we adjust the input image in the direction that maximizes the loss\n",
    "    input_img_data += grads_value * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    # Build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered.\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # Compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "\n",
    "    # Normalization trick: we normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # This function returns the loss and grads given the input picture\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    \n",
    "    # We start from a gray image with some noise\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "\n",
    "    # Run gradient ascent for 40 steps\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generate_pattern('block3_conv1', 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']:\n",
    "    size = 64\n",
    "    margin = 5\n",
    "\n",
    "    # This a empty (black) image where we will store our results.\n",
    "    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))\n",
    "\n",
    "    for i in range(8):  # iterate over the rows of our results grid\n",
    "        for j in range(8):  # iterate over the columns of our results grid\n",
    "            # Generate the pattern for filter `i + (j * 8)` in `layer_name`\n",
    "            filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
    "\n",
    "            # Put the result in the square `(i, j)` of the results grid\n",
    "            horizontal_start = i * size + i * margin\n",
    "            horizontal_end = horizontal_start + size\n",
    "            vertical_start = j * size + j * margin\n",
    "            vertical_end = vertical_start + size\n",
    "            results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
    "\n",
    "    # Display the results grid\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Note that we are including the densely-connected classifier on top;\n",
    "# all previous times, we were discarding it.\n",
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = '/Users/fchollet/Downloads/creative_commons_elephant.jpg'\n",
    "\n",
    "# `img` is a PIL image of size 224x224\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# `x` is a float32 Numpy array of shape (224, 224, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# We add a dimension to transform our array into a \"batch\"\n",
    "# of size (1, 224, 224, 3)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Finally we preprocess the batch\n",
    "# (this does channel-wise color normalization)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(preds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the \"african elephant\" entry in the prediction vector\n",
    "african_elephant_output = model.output[:, 386]\n",
    "\n",
    "# The is the output feature map of the `block5_conv3` layer,\n",
    "# the last convolutional layer in VGG16\n",
    "last_conv_layer = model.get_layer('block5_conv3')\n",
    "\n",
    "# This is the gradient of the \"african elephant\" class with regard to\n",
    "# the output feature map of `block5_conv3`\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\n",
    "\n",
    "# This is a vector of shape (512,), where each entry\n",
    "# is the mean intensity of the gradient over a specific feature map channel\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# This function allows us to access the values of the quantities we just defined:\n",
    "# `pooled_grads` and the output feature map of `block5_conv3`,\n",
    "# given a sample image\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "# These are the values of these two quantities, as Numpy arrays,\n",
    "# given our sample image of two elephants\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "# We multiply each channel in the feature map array\n",
    "# by \"how important this channel is\" with regard to the elephant class\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "# The channel-wise mean of the resulting feature map\n",
    "# is our heatmap of class activation\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# We use cv2 to load the original image\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# We resize the heatmap to have the same size as the original image\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# We convert the heatmap to RGB\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# We apply the heatmap to the original image\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# 0.4 here is a heatmap intensity factor\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "# Save the image to disk\n",
    "cv2.imwrite('/Users/fchollet/Downloads/elephant_cam.jpg', superimposed_img)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}